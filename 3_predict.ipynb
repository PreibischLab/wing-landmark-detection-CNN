{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, Add, MaxPooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import h5py\n",
    "from skimage import io, exposure\n",
    "\n",
    "# convenient imports\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "import cv2\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "#import sys\n",
    "#np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg');\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('Greys');\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"keras\", keras.__version__)\n",
    "print(\"tensorflow\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the backend the ordering of the channels\n",
    "print(keras.backend.backend())\n",
    "print(keras.backend.image_dim_ordering())\n",
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = 'YOURPATH'\n",
    "\n",
    "weights_file = '0600_0.0001'\n",
    "y_file = 'Y'\n",
    "\n",
    "im_size = 1024\n",
    "\n",
    "num_classes = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(input_shape, n_output_channels):\n",
    "\n",
    "    x_in = Input(input_shape)\n",
    "\n",
    "    x1 = Conv2D(n_conv, kernel_size=3, padding=\"same\", activation=\"relu\")(x_in)\n",
    "    x1 = Conv2D(n_conv, kernel_size=3, padding=\"same\", activation=\"relu\")(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    \n",
    "    x1_pool = MaxPooling2D(pool_size=2, strides=2, padding=\"same\")(x1)\n",
    "    x1_pool = Dropout(0.25)(x1_pool)\n",
    "    \n",
    "    x2 = Conv2D(n_conv*2, kernel_size=3, padding=\"same\", activation=\"relu\")(x1_pool)\n",
    "    x2 = Conv2D(n_conv*2, kernel_size=3, padding=\"same\", activation=\"relu\")(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    \n",
    "    x2_pool = MaxPooling2D(pool_size=2, strides=2, padding=\"same\")(x2)\n",
    "    x2_pool = Dropout(0.25)(x2_pool)\n",
    "\n",
    "    x3 = Conv2D(n_conv*4, kernel_size=3, padding=\"same\", activation=\"relu\")(x2_pool)\n",
    "    x3 = Conv2D(n_conv*4, kernel_size=3, padding=\"same\", activation=\"relu\")(x3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "\n",
    "    x4 = Conv2DTranspose(n_conv*2, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\")(x3)\n",
    "    x4 = Conv2D(n_conv*2, kernel_size=3, padding=\"same\", activation=\"relu\")(x4)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = Dropout(0.25)(x4)\n",
    "\n",
    "    x_out = Conv2DTranspose(n_output_channels, kernel_size=3, strides=2, padding=\"same\", activation=\"linear\")(x4)\n",
    "\n",
    "    # Compile\n",
    "    CNN = Model(inputs=x_in, outputs=x_out, name=\"CNN\")\n",
    "    CNN.compile(optimizer=Adam(), loss=\"mean_squared_error\")\n",
    "\n",
    "    return CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'model' in globals(): # check that the model is defined\n",
    "    del model \n",
    "\n",
    "## Load model + weights seperately\n",
    "model = cnn((im_size,im_size), num_classes)\n",
    "model.load_weights(os.path.join(parent_dir, 'models', f'{y_file}', f'{weights_file}.hdf5'))\n",
    "model.summary()\n",
    "\n",
    "#model = load_model('wing_models/nn-wing-gauss5.h5py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images:\n",
    "x = np.load(os.path.join(parent_dir, 'npy_data', f'X_masked.npy'))\n",
    "y = np.load(os.path.join(parent_dir, 'npy_data', f'Y_sig3.npy'))\n",
    "print(f'x size: {x.shape}')\n",
    "print(f'y size: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images:\n",
    "x_copy = np.load(os.path.join(parent_dir, 'npy_data', f'X_masked.npy'))\n",
    "y_copy = np.load(os.path.join(parent_dir, 'npy_data', f'Y_sig3.npy'))\n",
    "print(f'x size: {x.shape}')\n",
    "print(f'y size: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle \n",
    "x, y = shuffle(x, y, random_state=0)\n",
    "\n",
    "n_train = 550\n",
    "\n",
    "(x_train, y_train) = x[:n_train], y[:n_train]\n",
    "(x_test, y_test) = x[n_train:], y[n_train:]\n",
    "\n",
    "print(f'x train size: {x_train.shape}')\n",
    "print(f'x test size: {x_test.shape}')\n",
    "\n",
    "print(f'y train size: {y_train.shape}')\n",
    "print(f'y test size: {y_test.shape}')\n",
    "\n",
    "x_train = x_train.astype('float32')[:,:,:, None]\n",
    "x_test = x_test.astype('float32')[:,:,:, None]\n",
    "\n",
    "print(f'x train size: {x_train.shape}')\n",
    "print(f'x test size: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the test images - X & Y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save x_test:\n",
    "# xs_images_dir = os.path.join(parent_dir, 'images_xs_notnorm')\n",
    "# os.makedirs(xs_images_dir, exist_ok=True)\n",
    "\n",
    "# for i in range(x_test.shape[0]):\n",
    "    \n",
    "#     temp = x_test[i,:,:,0]\n",
    "#     max_temp = max(np.absolute([np.min(x_test), np.max(x_test)]))\n",
    "#     temp = exposure.equalize_hist(temp)\n",
    "#     io.imsave(os.path.join(xs_dir, f'{i}.png'), temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save y_test - true values, not predictions\n",
    "\n",
    "ys_im_dir = os.path.join(parent_dir, 'images_ys', 'sig3')\n",
    "os.makedirs(ys_im_dir, exist_ok=True)\n",
    "\n",
    "for i in range(x_test.shape[0]):\n",
    "    for j in range(num_classes):\n",
    "        io.imsave(os.path.join(ys_im_dir, f'{i}_{j}.png'), (y_test[i,:,:,j]).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions \n",
    "\n",
    "pred_dir = os.path.join(parent_dir, 'images_predictions', f'sig3_xMasked')\n",
    "os.makedirs(pred_dir, exist_ok=True)\n",
    "\n",
    "for i in range(x_test.shape[0]):\n",
    "    \n",
    "    sample = x_test[[i]]\n",
    "    predicted = model.predict(sample)\n",
    "    predicted[predicted<0] = 0\n",
    "    predicted = predicted/np.max(predicted)\n",
    "    \n",
    "    for j in range(num_classes):\n",
    "        \n",
    "        io.imsave(os.path.join(pred_dir, f'{i}_{j}.png'), predicted[0,:,:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions not normed:\n",
    "\n",
    "pred_notnormed_dir = os.path.join(parent_dir, 'images_predictions_notnormed', f'sig3_xMasked')\n",
    "os.makedirs(pred_notnormed_dir, exist_ok=True)\n",
    "\n",
    "for i in range(x_test.shape[0]):\n",
    "    \n",
    "    sample = x_test[[i]]\n",
    "    predicted = model.predict(sample)\n",
    "    \n",
    "    predicted[predicted<0] = 0\n",
    "    predicted = (predicted*1000).astype(np.int16)\n",
    "    \n",
    "    for j in range(num_classes):\n",
    "        \n",
    "        io.imsave(os.path.join(pred_notnormed_dir, f'{i}_{j}.png'), predicted[0,:,:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(predicted[0,:,:,20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the REAL landmarks on the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to display Y images - each landmark has own color:\n",
    "\n",
    "# sns.color_palette('colorblind', 3) - has 3 colors\n",
    "# [1] takes the second color in the scheme, 256 displays 256 shades of that color\n",
    "sns.palplot(sns.light_palette(sns.color_palette('colorblind', 3)[1], 256))\n",
    "\n",
    "# Array of all those colors\n",
    "#my_color_scale = sns.light_palette('green',256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Images:\n",
    "Real landmarks display, with some radius around it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "\n",
    "# mama_dir = '/home/ella/Desktop/wings_for_RF/'\n",
    "\n",
    "# img_folder = os.path.join(mama_dir, 'data/images/')\n",
    "# landmarks_folder = os.path.join(mama_dir, 'ldmks/raw/')\n",
    "\n",
    "# all_images_files = [f for f in glob.glob(os.path.join(img_folder,'*'))]\n",
    "# all_landmarks_files = [f for f in glob.glob(os.path.join(landmarks_folder,'*'))] \n",
    "\n",
    "# all_images_names = [os.path.basename(f)[:-4] for f in all_images_files]\n",
    "# all_landmarks_names = [os.path.basename(f)[:-4] for f in all_landmarks_files]\n",
    "\n",
    "# # sort all lists to be on the same order\n",
    "# images_lists = zip(all_images_names, all_images_files)\n",
    "# landmarks_lists = zip(all_landmarks_names, all_landmarks_files)\n",
    "\n",
    "# images_lists_s = list(sorted(images_lists))\n",
    "# landmarks_lists_s = list(sorted(landmarks_lists))\n",
    "\n",
    "# n_lm = 40\n",
    "\n",
    "# # All images landmarks read - to list of np arrays:\n",
    "# ims_landmarks = []\n",
    "# for l in landmarks_lists_s:\n",
    "#     lines = [line.rstrip('\\n') for line in open(l[1])]\n",
    "#     ims_landmarks.append(np.asarray([f.split(\" \") for f in lines]).astype(np.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = 1\n",
    "\n",
    "# # Load image:\n",
    "# x_im = io.imread(images_lists_s[im][1])   \n",
    "\n",
    "# #thr = 0.95\n",
    "# my_img = np.ones((3234, 3840,3))\n",
    "\n",
    "# lms = ims_landmarks[im]\n",
    "\n",
    "# r_lm = [0,1,5,10,2,7,8,9,3,11,12,13]\n",
    "\n",
    "# r_lm = [i for i in range(40)]\n",
    "\n",
    "# for l in range(len(r_lm)):\n",
    "    \n",
    "#     temp = np.ones((3234, 3840))\n",
    "#     lm = lms[l]\n",
    "    \n",
    "#     temp[int(lm[1]),int(lm[0])] = 0\n",
    "    \n",
    "#     my_color_scale = sns.light_palette(sns.color_palette(\"Paired\", 40)[l], 256)\n",
    "#     my_color_scale[0] = [1,1,1]\n",
    "    \n",
    "#     color = my_color_scale[-1][0]\n",
    "    \n",
    "#     radi = 40\n",
    "#     for i in range(radi):\n",
    "#         for j in range(radi):\n",
    "#             for ch in range(3):\n",
    "#                 my_img[int(lm[1])-j,int(lm[0])-i,ch] = my_color_scale[-1][ch]\n",
    "#                 my_img[int(lm[1])-j,int(lm[0])+i,ch] = my_color_scale[-1][ch]\n",
    "#                 my_img[int(lm[1])+j,int(lm[0])-i,ch] = my_color_scale[-1][ch]\n",
    "#                 my_img[int(lm[1])+j,int(lm[0])+i,ch] = my_color_scale[-1][ch]\n",
    "\n",
    "# # Normalize X:\n",
    "# x_show = ((x_im-np.min(x_im))/(np.max(x_im)-np.min(x_im))).astype(np.float64)\n",
    "# x_show = np.repeat(x_show[:,:,np.newaxis],3,axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_img = cv2.addWeighted(x_show, 0.25, my_img, 0.8, 0)\n",
    "\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.imshow(new_img, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Image:\n",
    "Real Values - Y from yann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = 6 \n",
    "thr = 0.95\n",
    "\n",
    "lm_img_clr = np.ones((im_size,im_size,3))\n",
    "lm_img_bw = np.ones((im_size,im_size))\n",
    "\n",
    "r_lm = [0,1,5,10,2,7,8,9,3,11,12,13]\n",
    "lm = [i for i in range(40)]\n",
    "\n",
    "for l in range(len(lm)):\n",
    "    \n",
    "    # Take current landmark image:\n",
    "    temp = y_test[im,:,:,lm[l]].copy()\n",
    "    temp[temp<thr] = thr\n",
    "    temp = ((temp-np.min(temp))/(np.max(temp)-np.min(temp)) * 255).astype(np.uint8)\n",
    "    \n",
    "    my_color_scale = sns.light_palette(sns.color_palette(\"Paired\", 40)[l], 256) \n",
    "    #my_color_scale[0] = [1,1,1]\n",
    "    \n",
    "    for i in range(temp.shape[0]):\n",
    "        for j in range(temp.shape[1]):\n",
    "            if temp[i,j] != 0:\n",
    "                \n",
    "                # Black and white image:\n",
    "                lm_img_bw[i,j] = np.mean([lm_img_bw[i,j], temp[i,j]])\n",
    "                \n",
    "                # \n",
    "                lm_img_clr[i,j,0] = np.mean([lm_img_clr[i,j,0], my_color_scale[temp[i,j]][0]])\n",
    "                lm_img_clr[i,j,1] = np.mean([lm_img_clr[i,j,1], my_color_scale[temp[i,j]][1]])\n",
    "                lm_img_clr[i,j,2] = np.mean([lm_img_clr[i,j,2], my_color_scale[temp[i,j]][2]])\n",
    "\n",
    "# Normalize X:\n",
    "x_show = x_test[im,:,:,0] + np.min(x_test[im,:,:,0])\n",
    "x_show = ((x_show-np.min(x_show))/(np.max(x_show)-np.min(x_show))).astype(np.float64)\n",
    "\n",
    "x_show = np.repeat(x_show[:,:,np.newaxis],3,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show bw landmarks image:\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(lm_img_bw, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show color image:\n",
    "new_img = cv2.addWeighted(x_show, 0.2, lm_img_clr, 0.8, 0)\n",
    "new_img = cv2.addWeighted(x_show, 0.2, lm_img_clr, 0.83, 0)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(new_img, interpolation='none')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if 'model' in globals(): # check that the model is defined\n",
    "#    del model \n",
    "\n",
    "#model = load_model('/home/ella/Desktop/wings_for_RF/forDL/wing_models/nn-wing-gauss5.h5py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display 9 consecutive images:\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, sharex=True, sharey=True, figsize=(20,13))\n",
    "\n",
    "# How many highest values to display:\n",
    "n_pix_per_lm = 5\n",
    "\n",
    "im_num = 23\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "\n",
    "        sample = x_test[[im_num]]\n",
    "        predicted = model.predict(sample)\n",
    "\n",
    "        # Normalize X:\n",
    "        x_show = sample[0,:,:,0] + np.min(sample[0,:,:,0])\n",
    "        x_show = ((x_show-np.min(x_show))/(np.max(x_show)-np.min(x_show))).astype(np.float64)\n",
    "        x_show = np.repeat(x_show[:,:,np.newaxis],3,axis=2)\n",
    "\n",
    "        pred_show = np.ones((im_size,im_size,3))\n",
    "\n",
    "        #r_lm = [0,1,5,10,2,7,8,9,3,11,12,13]\n",
    "        lm = [i for i in range(40)]\n",
    "        for l in range(len(lm)):\n",
    "            temp = predicted[0,:,:,lm[l]].copy()\n",
    "\n",
    "            # Take x highest values:\n",
    "            val = (np.sort(temp.reshape(-1)))[-n_pix_per_lm]\n",
    "            temp = np.where(temp>=val, 1, 0)\n",
    "\n",
    "            temp = ((temp-np.min(temp))/(np.max(temp)-np.min(temp)) * 255).astype(np.uint8)\n",
    "            my_color_scale = sns.light_palette(sns.color_palette(\"Paired\", 40)[l], 256)\n",
    "            my_color_scale = sns.light_palette(sns.color_palette(\"bright\", 40)[l], 256)\n",
    "            my_color_scale[0] = [1,1,1]\n",
    "            \n",
    "            for i in range(temp.shape[0]):\n",
    "                for j in range(temp.shape[1]):\n",
    "                    if temp[i,j] != 0:\n",
    "                        pred_show[i,j,0] = np.mean([pred_show[i,j,0], my_color_scale[temp[i,j]][0]])\n",
    "                        pred_show[i,j,1] = np.mean([pred_show[i,j,1], my_color_scale[temp[i,j]][1]])\n",
    "                        pred_show[i,j,2] = np.mean([pred_show[i,j,2], my_color_scale[temp[i,j]][2]])\n",
    "\n",
    "        new_img = cv2.addWeighted(x_show, 0.15, pred_show, 0.8, 0)\n",
    "        col.imshow(new_img, vmin=0, vmax=1)\n",
    "        col.axis('off')\n",
    "        \n",
    "        im_num+=1\n",
    "        \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 9 consecutive images:\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, sharex=True, sharey=True, figsize=(20,13))\n",
    "\n",
    "# How many highest values to display:\n",
    "n_pix_per_lm = 5\n",
    "\n",
    "im_num = 23\n",
    "for row in ax:\n",
    "    for col in row:\n",
    "\n",
    "        sample = x_test[[im_num]]\n",
    "        predicted = model.predict(sample)\n",
    "\n",
    "        # Normalize X:\n",
    "        x_show = sample[0,:,:,0] + np.min(sample[0,:,:,0])\n",
    "        x_show = ((x_show-np.min(x_show))/(np.max(x_show)-np.min(x_show))).astype(np.float64)\n",
    "        x_show = np.repeat(x_show[:,:,np.newaxis],3,axis=2)\n",
    "\n",
    "        pred_show = np.ones((im_size,im_size,3))\n",
    "\n",
    "        #r_lm = [0,1,5,10,2,7,8,9,3,11,12,13]\n",
    "        lm = [i for i in range(40)]\n",
    "        for l in range(len(lm)):\n",
    "            temp = predicted[0,:,:,lm[l]].copy()\n",
    "\n",
    "            # Take x highest values:\n",
    "            val = (np.sort(temp.reshape(-1)))[-n_pix_per_lm]\n",
    "            temp = np.where(temp>=val, 1, 0)\n",
    "\n",
    "            temp = ((temp-np.min(temp))/(np.max(temp)-np.min(temp)) * 255).astype(np.uint8)\n",
    "            my_color_scale = sns.light_palette(sns.color_palette(\"Paired\", 40)[l], 256)\n",
    "            my_color_scale = sns.light_palette(sns.color_palette(\"bright\", 40)[l], 256)\n",
    "            my_color_scale[0] = [1,1,1]\n",
    "            \n",
    "            for i in range(temp.shape[0]):\n",
    "                for j in range(temp.shape[1]):\n",
    "                    if temp[i,j] != 0:\n",
    "                        pred_show[i,j,0] = np.mean([pred_show[i,j,0], my_color_scale[temp[i,j]][0]])\n",
    "                        pred_show[i,j,1] = np.mean([pred_show[i,j,1], my_color_scale[temp[i,j]][1]])\n",
    "                        pred_show[i,j,2] = np.mean([pred_show[i,j,2], my_color_scale[temp[i,j]][2]])\n",
    "\n",
    "        new_img = cv2.addWeighted(x_show, 0.15, pred_show, 0.8, 0)\n",
    "        col.imshow(new_img, vmin=0, vmax=1)\n",
    "        col.axis('off')\n",
    "        \n",
    "        im_num+=1\n",
    "        \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_show[-1,-1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on full size images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_names_file = '/PARENT_DIR/original_files_list.txt'\n",
    "\n",
    "# original_files = [line.rstrip('\\n') for line in open(original_names_file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_4display, original_files = shuffle(x_copy, original_files, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(original_files[586])\n",
    "# print(original_files[589])\n",
    "# print(original_files[591])\n",
    "# print(original_files[594])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "\n",
    "# img_folder = os.path.join(parent_dir, 'data/images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### SUPER LONG RUN!!!!\n",
    "\n",
    "# for im in range(550,600):\n",
    "\n",
    "#     # Load image:\n",
    "#     #x_im = io.imread(images_lists_s[im][1])   \n",
    "#     x_im = io.imread(os.path.join(img_folder,f'{original_files[im]}.tif'))\n",
    "\n",
    "#     #sample = x_test[[im-550]]\n",
    "#     sample = x_test[[im-550]]\n",
    "#     predicted = model.predict(sample)\n",
    "\n",
    "#     # Normalize X:\n",
    "#     x_show = x_im / np.max(x_im)\n",
    "#     x_show = np.repeat(x_show[:,:,np.newaxis],3,axis=2)\n",
    "\n",
    "#     pred_show = np.ones((3234, 3840,3))\n",
    "\n",
    "#     n_pix_per_lm = 600\n",
    "\n",
    "#     lm = [i for i in range(40)]\n",
    "#     for l in range(len(lm)):\n",
    "\n",
    "#         temp = resize(predicted[0,30:,:,lm[l]], (3234, 3840))\n",
    "#         #io.imsave(f'/home/ella/Desktop/for_stephan/{im}_{l}.tif', temp.astype(np.float32))\n",
    "\n",
    "#         # Take x highest values:\n",
    "#         val = (np.sort(temp.reshape(-1)))[-n_pix_per_lm]\n",
    "#         temp = np.where(temp>=val, 1, 0)\n",
    "\n",
    "#         temp = ((temp-np.min(temp))/(np.max(temp)-np.min(temp)) * 255).astype(np.uint8)\n",
    "\n",
    "#         my_color_scale = sns.light_palette(sns.color_palette(\"Paired\", 40)[l], 256)\n",
    "#         my_color_scale[0] = [1,1,1]\n",
    "\n",
    "#         for i in range(temp.shape[0]):\n",
    "#             for j in range(temp.shape[1]):\n",
    "#                 if temp[i,j] != 0:\n",
    "#                     pred_show[i,j,0] = np.mean([pred_show[i,j,0], my_color_scale[temp[i,j]][0]])\n",
    "#                     pred_show[i,j,1] = np.mean([pred_show[i,j,1], my_color_scale[temp[i,j]][1]])\n",
    "#                     pred_show[i,j,2] = np.mean([pred_show[i,j,2], my_color_scale[temp[i,j]][2]])\n",
    "\n",
    "#     new_img = cv2.addWeighted(x_show, 0.2, pred_show, 0.8, 0)\n",
    "\n",
    "#     io.imsave(f'/home/ella/Desktop/{im}.png', new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_img = cv2.addWeighted(x_show, 0.2, pred_show, 0.8, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #new_img = cv2.addWeighted(x_show, 0.25, my_img, 0.8, 0)\n",
    "\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.imshow(new_img, interpolation='none')\n",
    "# plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
